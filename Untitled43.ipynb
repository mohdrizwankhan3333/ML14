{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37939e19-4bd7-443f-a780-8fadd4e13596",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q1. What is the purpose of grid search CV in machine learning, and how does it work?\n",
    "\n",
    "Grid search CV tunes hyperparameters by exhaustively searching over a specified parameter grid using cross-validation, selecting the combination that yields the best model performance.\n",
    "\n",
    "### Q2. Describe the difference between grid search CV and randomized search CV, and when might you choose one over the other?\n",
    "\n",
    "Grid search CV explores all possible parameter combinations, while randomized search CV samples a subset. Randomized search is preferred for large parameter spaces to save computational resources.\n",
    "\n",
    "### Q3. What is data leakage, and why is it a problem in machine learning? Provide an example.\n",
    "\n",
    "Data leakage occurs when information from outside the training dataset influences the model, leading to overestimation of performance. Example: Using future data in training.\n",
    "\n",
    "### Q4. How can you prevent data leakage when building a machine learning model?\n",
    "\n",
    "Prevent data leakage by strictly separating training and testing datasets, avoiding using future information, and ensuring feature engineering occurs within cross-validation folds.\n",
    "\n",
    "### Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?\n",
    "\n",
    "A confusion matrix summarizes prediction results, showing true positives, true negatives, false positives, and false negatives, which helps evaluate a classification model’s accuracy and error types.\n",
    "\n",
    "### Q6. Explain the difference between precision and recall in the context of a confusion matrix.\n",
    "\n",
    "Precision measures the accuracy of positive predictions (TP/(TP+FP)), while recall measures the ability to identify all positive instances (TP/(TP+FN)). Both are crucial for model evaluation.\n",
    "\n",
    "### Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?\n",
    "\n",
    "Analyze the matrix's false positives and false negatives to identify specific error types, informing adjustments to improve the model’s performance on misclassified cases.\n",
    "\n",
    "### Q8. What are some common metrics that can be derived from a confusion matrix, and how are they calculated?\n",
    "\n",
    "Common metrics: Accuracy ((TP+TN)/total), Precision (TP/(TP+FP)), Recall (TP/(TP+FN)), F1-Score (2*(Precision*Recall)/(Precision+Recall)), providing insights into the model’s overall and class-specific performance.\n",
    "\n",
    "### Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?\n",
    "\n",
    "Accuracy measures the proportion of correctly classified instances ((TP+TN)/total), directly reflecting the values in the confusion matrix and indicating the model's overall correctness.\n",
    "\n",
    "### Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning model?\n",
    "\n",
    "Identify biases by examining disproportionate error rates across classes, indicating model limitations. Adjust the model or training data to address these biases and improve fairness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
